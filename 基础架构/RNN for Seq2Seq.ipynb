{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e6c7ecc-1509-43d5-b76d-9e0e675c30d3",
   "metadata": {},
   "source": [
    "# RNN for Seq2Seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3607fa3-00cf-4835-b75c-857100ce045a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e09afe-7d05-46eb-b382-14f81d6391fd",
   "metadata": {},
   "source": [
    "## 数据生成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "248c93ea-c76f-47e8-b251-1d87be873f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sequences(n=128, variable_len=False, seed=13):\n",
    "    basic_corners = np.array([[-1, -1], [-1, 1], [1, 1], [1, -1]])\n",
    "    np.random.seed(seed)\n",
    "    bases = np.random.randint(4, size=n)\n",
    "    if variable_len:\n",
    "        lengths = np.random.randint(3, size=n) + 2\n",
    "    else:\n",
    "        lengths = [4] * n\n",
    "    directions = np.random.randint(2, size=n)\n",
    "    points = [basic_corners[[(b + i) % 4 for i in range(4)]][slice(None, None, d*2-1)][:l] + np.random.randn(l, 2) * 0.1 for b, d, l in zip(bases, directions, lengths)]\n",
    "    return points, directions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "044a182a-df81-42f0-a169-92f385811fb3",
   "metadata": {},
   "source": [
    "## Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "3bcd570d-8a00-466c-89c5-5f2249b4321d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, hidden_dim, n_features, num_layers=1):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_features = n_features\n",
    "        self.num_layers = num_layers\n",
    "        self.hidden = None\n",
    "        self.rnn = nn.GRU(self.n_features, self.hidden_dim, self.num_layers, batch_first=True)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        output, self.hidden = self.rnn(X)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a1a87fe1-8365-4ecd-b6e5-bbc1498eebb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_seq = torch.tensor([[-1, -1], [-1, 1], [1, 1], [1, -1]]).float().view(1, 4, 2)\n",
    "source_seq = full_seq[:, :2] # first two corners\n",
    "target_seq = full_seq[:, 2:] # last two corners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "693d35d4-5c65-4936-987a-607782d7a282",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[-1., -1.],\n",
       "          [-1.,  1.],\n",
       "          [ 1.,  1.],\n",
       "          [ 1., -1.]]]),\n",
       " tensor([[[-1., -1.],\n",
       "          [-1.,  1.]]]),\n",
       " tensor([[[ 1.,  1.],\n",
       "          [ 1., -1.]]]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_seq, source_seq, target_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f4d769db-e888-4125-8dbc-57319be52186",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(21)\n",
    "encoder = Encoder(n_features=2, hidden_dim=2)\n",
    "hidden_seq = encoder(source_seq)\n",
    "hidden_final = hidden_seq[:, -1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f7ab0467-0fa9-4028-be0b-ecae07b88023",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.3105, -0.5263]]], grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_final"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea0a5e0-ed3f-4155-8016-099ad83817e8",
   "metadata": {},
   "source": [
    "## Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fc71ced5-aaff-4945-ae29-8fdd2e3db5f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, hidden_dim, n_features, num_layers=1):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_features = n_features\n",
    "        self.num_layers = num_layers\n",
    "        self.hidden = None\n",
    "        self.rnn = nn.GRU(self.n_features, self.hidden_dim, self.num_layers, batch_first=True)\n",
    "        self.regression = nn.Linear(self.hidden_dim, self.n_features)\n",
    "        \n",
    "    def init_hidden(self, hidden_seq):\n",
    "        hidden_final = hidden_seq[:, -1:]\n",
    "        self.hidden = hidden_final.permute(1, 0, 2)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        output, self.hidden = self.rnn(X, self.hidden)\n",
    "        last_output = output[:, -1:]\n",
    "        out = self.regression(last_output)\n",
    "        \n",
    "        return out.view(-1, 1, self.n_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f19cb29a-73d5-4a37-b6e6-9d521f8185ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden tensor([[[ 0.3105, -0.5263]]], grad_fn=<PermuteBackward0>)\n",
      "Output tensor([[[-0.2339,  0.4702]]], grad_fn=<ViewBackward0>)\n",
      "\n",
      "Hidden tensor([[[ 0.3913, -0.6853]]], grad_fn=<StackBackward0>)\n",
      "Output tensor([[[-0.0226,  0.4628]]], grad_fn=<ViewBackward0>)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(21)\n",
    "decoder = Decoder(n_features=2, hidden_dim=2)\n",
    "decoder.init_hidden(hidden_seq)\n",
    "inputs = source_seq[:, -1:]\n",
    "\n",
    "target_len = 2\n",
    "for i in range(target_len):\n",
    "    print(f'Hidden {decoder.hidden}')\n",
    "    out = decoder(inputs)\n",
    "    print(f'Output {out}\\n')\n",
    "    \n",
    "    inputs = out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b30651-d181-4219-a4e2-e6097296f610",
   "metadata": {},
   "source": [
    "## Teacher forcing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "78dd5317-32bc-4ba1-8b14-045caa22b433",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden tensor([[[ 0.3105, -0.5263]]], grad_fn=<PermuteBackward0>)\n",
      "Output tensor([[[-0.2339,  0.4702]]], grad_fn=<ViewBackward0>)\n",
      "\n",
      "Hidden tensor([[[ 0.3913, -0.6853]]], grad_fn=<StackBackward0>)\n",
      "Output tensor([[[-0.0226,  0.4628]]], grad_fn=<ViewBackward0>)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(21)\n",
    "decoder = Decoder(n_features=2, hidden_dim=2)\n",
    "decoder.init_hidden(hidden_seq)\n",
    "inputs = source_seq[:, -1:]\n",
    "\n",
    "teacher_forcing_prob = 0.5\n",
    "target_len = 2\n",
    "for i in range(target_len):\n",
    "    print(f'Hidden {decoder.hidden}')\n",
    "    out = decoder(inputs)\n",
    "    print(f'Output {out}\\n')\n",
    "    \n",
    "    if torch.rand(1) <= teacher_forcing_prob:\n",
    "        inputs = target_seq[:, i:i+1]\n",
    "    else:\n",
    "        inputs = out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9336c79d-ae57-49bf-afbf-b2b7e8d943a4",
   "metadata": {},
   "source": [
    "## Encoder + Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "4b6a807b-b8fd-4cab-a4f2-98b769ebe87b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderDecoder(nn.Module):\n",
    "    def __init__(self, encoder, decoder, input_len, target_len, teacher_forcing_prob):\n",
    "        super(EncoderDecoder, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.input_len = input_len\n",
    "        self.target_len = target_len\n",
    "        self.teacher_forcing_prob = teacher_forcing_prob\n",
    "        self.outputs = None\n",
    "    \n",
    "    def init_outputs(self, batch_size):\n",
    "        self.outputs = torch.zeros(batch_size, self.target_len, self.encoder.n_features)\n",
    "    \n",
    "    def store_output(self, i, out):\n",
    "        self.outputs[:, i:i+1, :] = out\n",
    "        \n",
    "    def forward(self, X):\n",
    "        source_seq = X[:, :self.input_len, :]\n",
    "        target_seq = X[:, self.input_len:, :]\n",
    "        self.init_outputs(X.shape[0])\n",
    "        \n",
    "        hidden_seq = self.encoder(source_seq)\n",
    "        self.decoder.init_hidden(hidden_seq)\n",
    "        \n",
    "        des_inputs = source_seq[:, -1:]\n",
    "        \n",
    "        for i in range(self.target_len):\n",
    "            out = self.decoder(des_inputs)\n",
    "            self.store_output(i, out)\n",
    "            \n",
    "            prob = self.teacher_forcing_prob\n",
    "            \n",
    "            if not self.training:\n",
    "                prob = 0\n",
    "            \n",
    "            if torch.rand(1) <= prob:\n",
    "                des_inputs = target_seq[:, i:i+1, :]\n",
    "            else:\n",
    "                des_inputs = out\n",
    "        return self.outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "c91246af-439b-431e-97c7-5637f78b4c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "encdec = EncoderDecoder(encoder, decoder, input_len=2, target_len=2, teacher_forcing_prob=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "4259091e-8ede-42fb-89bc-43ca791fe85f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.2339,  0.4702],\n",
       "         [ 0.2265,  0.4529]]], grad_fn=<CopySlices>)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encdec.train()\n",
    "encdec(full_seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea6c9cd-2b00-4a2a-9a98-0cdbca3e6d4c",
   "metadata": {},
   "source": [
    "## 附录"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2711e064-0df3-4197-b29a-e2c4f2986286",
   "metadata": {},
   "source": [
    "## 张量运算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "6b71f63b-0494-4ff2-80e7-5af390e7a232",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.4564, -0.7840,  0.1247, -0.9606, -0.6569],\n",
       "         [-0.7334,  0.1145, -1.0212,  0.1640,  1.6930],\n",
       "         [ 0.0648,  0.4329, -0.1878, -1.6598,  0.8662],\n",
       "         [ 2.1388, -0.9376, -1.1139,  0.0666,  0.0629],\n",
       "         [ 0.8676,  0.4623, -0.1737, -0.4213,  0.6469],\n",
       "         [-0.9211, -0.1064, -0.9334,  0.9722,  1.2287],\n",
       "         [-0.0681, -1.2094,  0.0790,  0.3298, -0.7183],\n",
       "         [-1.6490,  2.4531,  1.4808, -0.9764, -1.3599],\n",
       "         [-0.4461, -0.8618, -0.1400, -1.4759,  1.7178],\n",
       "         [ 2.1376,  1.3808, -0.5966, -0.5782, -0.0857]],\n",
       "\n",
       "        [[-1.5045, -0.0218,  2.0812,  2.8357, -0.4534],\n",
       "         [-0.6158, -1.6141,  1.2543,  0.5157,  0.4364],\n",
       "         [-0.2901,  0.6084,  1.3221, -0.0471,  0.4305],\n",
       "         [-0.5746, -0.1764, -0.0164,  2.0941,  0.2338],\n",
       "         [ 1.8353, -0.1671, -1.1604, -0.6550, -0.4926],\n",
       "         [ 0.7152,  0.0294,  0.6620, -0.2393,  1.1722],\n",
       "         [ 0.0397,  1.8118, -1.2269, -0.4904,  1.2061],\n",
       "         [ 0.4260, -0.3638,  0.9938, -1.6244, -0.1448],\n",
       "         [ 0.0886, -0.2212, -0.8251, -1.0593,  0.9217],\n",
       "         [ 0.4172,  0.9692,  1.6687,  0.6110, -1.4135]],\n",
       "\n",
       "        [[-0.5241,  2.4863, -0.3260,  0.4464, -0.0639],\n",
       "         [-0.5079,  1.5866, -0.3553, -0.1205, -0.3859],\n",
       "         [-1.6351,  0.2871,  0.7942, -0.8115, -0.1827],\n",
       "         [ 2.1249, -0.7217,  0.6425,  0.8059, -1.9808],\n",
       "         [-1.6275,  0.0575,  0.5534, -2.7447, -0.0216],\n",
       "         [-1.9632,  1.5303,  0.2050,  0.2651,  0.7813],\n",
       "         [-1.2234,  1.1095,  0.2734,  0.9613,  0.7538],\n",
       "         [ 0.8061,  0.6563, -1.2902, -0.1474, -0.5720],\n",
       "         [ 0.6610, -0.6686, -0.6379,  0.2654,  1.7192],\n",
       "         [ 0.6346, -0.0921, -0.2599,  1.8829,  1.0246]],\n",
       "\n",
       "        [[ 0.1964,  0.3782,  0.5305, -1.0835, -0.1533],\n",
       "         [-0.0122, -1.3114,  0.1299,  0.8989,  0.0366],\n",
       "         [ 0.6419,  0.0457, -0.3778,  0.7756,  0.4564],\n",
       "         [-0.1002,  0.8078, -0.1036, -0.5452,  1.4473],\n",
       "         [ 0.9496, -0.9560,  0.6597, -0.4945, -0.1129],\n",
       "         [-0.7128, -1.0182, -1.1165,  0.6290,  0.9476],\n",
       "         [-1.2306,  0.3731, -1.4703,  1.8423, -0.1005],\n",
       "         [ 0.2082,  0.7143, -0.2307,  0.4706, -0.4541],\n",
       "         [ 0.5234,  0.7230, -0.0528,  1.3843,  0.8189],\n",
       "         [-0.8092, -1.5832, -0.7156,  0.2863,  0.8670]],\n",
       "\n",
       "        [[ 0.5502, -1.1774,  0.1485,  0.1360,  0.8631],\n",
       "         [ 1.2926, -0.0440, -1.4618, -0.7746, -0.8272],\n",
       "         [ 0.5184,  1.3051, -0.1559, -0.7755, -0.4430],\n",
       "         [-0.4034, -1.2519,  0.4126,  1.4619,  0.0633],\n",
       "         [-0.5033, -0.2723,  0.1837,  2.0644, -0.5983],\n",
       "         [ 1.8733,  0.6237, -1.1800,  1.1088,  0.0064],\n",
       "         [-0.0486, -0.2789, -0.3159, -0.9022,  1.1637],\n",
       "         [-0.9753,  0.7045, -1.8406, -0.1021,  0.5408],\n",
       "         [ 0.5090, -0.2031,  0.0990,  0.0333, -2.2990],\n",
       "         [ 1.1259, -0.7252, -2.4818, -2.1175, -0.1668]]])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_3d = torch.randn(5, 10, 5)\n",
    "tensor_3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "8840cce8-590e-4e2a-a9af-ff464936ac4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2.1376,  1.3808, -0.5966, -0.5782, -0.0857],\n",
       "        [ 0.4172,  0.9692,  1.6687,  0.6110, -1.4135],\n",
       "        [ 0.6346, -0.0921, -0.2599,  1.8829,  1.0246],\n",
       "        [-0.8092, -1.5832, -0.7156,  0.2863,  0.8670],\n",
       "        [ 1.1259, -0.7252, -2.4818, -2.1175, -0.1668]])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_3d[:,-1] #取出每一个batch的最后一个并降低维度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "ff8b94be-2ea4-4452-809f-c70fc94a40f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 2.1376,  1.3808, -0.5966, -0.5782, -0.0857]],\n",
       "\n",
       "        [[ 0.4172,  0.9692,  1.6687,  0.6110, -1.4135]],\n",
       "\n",
       "        [[ 0.6346, -0.0921, -0.2599,  1.8829,  1.0246]],\n",
       "\n",
       "        [[-0.8092, -1.5832, -0.7156,  0.2863,  0.8670]],\n",
       "\n",
       "        [[ 1.1259, -0.7252, -2.4818, -2.1175, -0.1668]]])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_3d[:, -1:,:] #取出每一个batch的最后一个且保留维度 等价于tensor_3d[:, -1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "1384374c-6b87-4167-885a-dd2cbee2c0dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.4564, -0.7840,  0.1247, -0.9606, -0.6569],\n",
       "         [-0.7334,  0.1145, -1.0212,  0.1640,  1.6930],\n",
       "         [ 0.0648,  0.4329, -0.1878, -1.6598,  0.8662]],\n",
       "\n",
       "        [[-1.5045, -0.0218,  2.0812,  2.8357, -0.4534],\n",
       "         [-0.6158, -1.6141,  1.2543,  0.5157,  0.4364],\n",
       "         [-0.2901,  0.6084,  1.3221, -0.0471,  0.4305]],\n",
       "\n",
       "        [[-0.5241,  2.4863, -0.3260,  0.4464, -0.0639],\n",
       "         [-0.5079,  1.5866, -0.3553, -0.1205, -0.3859],\n",
       "         [-1.6351,  0.2871,  0.7942, -0.8115, -0.1827]],\n",
       "\n",
       "        [[ 0.1964,  0.3782,  0.5305, -1.0835, -0.1533],\n",
       "         [-0.0122, -1.3114,  0.1299,  0.8989,  0.0366],\n",
       "         [ 0.6419,  0.0457, -0.3778,  0.7756,  0.4564]],\n",
       "\n",
       "        [[ 0.5502, -1.1774,  0.1485,  0.1360,  0.8631],\n",
       "         [ 1.2926, -0.0440, -1.4618, -0.7746, -0.8272],\n",
       "         [ 0.5184,  1.3051, -0.1559, -0.7755, -0.4430]]])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_3d[:,0:3,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee83c8a2-7b94-473f-aa83-b6b610f83039",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
